{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习入门__一元线性回归\n",
    "---\n",
    "pytorch官网<https://pytorch.org/get-started/locally/>\n",
    "安装后测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0368, 0.9990, 0.1715],\n",
      "        [0.4890, 0.2611, 0.2550],\n",
      "        [0.5961, 0.2189, 0.6499],\n",
      "        [0.3844, 0.3031, 0.0303],\n",
      "        [0.9662, 0.9835, 0.3657]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "# 结果：tensor([[0.3380, 0.3845, 0.3217],\n",
    "#              [0.8337, 0.9050, 0.2650],\n",
    "#              [0.2979, 0.7141, 0.9069],\n",
    "#              [0.1449, 0.1132, 0.1375],\n",
    "#              [0.4675, 0.3947, 0.1426]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.术语\n",
    "- 1. 损失函数 \n",
    "---\n",
    "## 1.2 张量（Tensors）\n",
    "-  它相当于Numpy的多维数组，相较于Numpy,Tensors可以应用到GPU上加快计算速度\n",
    "-  使用时需要导入库 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 声明和定义\n",
    "- torch.empty(): 声明一个未初始化的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0733e-02, 5.8154e-43, 1.0733e-02],\n",
      "        [5.8154e-43, 1.0733e-02, 5.8154e-43],\n",
      "        [1.0733e-02, 5.8154e-43, 1.0733e-02],\n",
      "        [5.8154e-43, 1.0733e-02, 5.8154e-43],\n",
      "        [1.0733e-02, 5.8154e-43, 1.0733e-02]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5*3 的矩阵\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.rand()：随机初始化一个矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9103, 0.9657, 0.9800],\n",
      "        [0.4060, 0.0491, 0.3156],\n",
      "        [0.1021, 0.0187, 0.4443],\n",
      "        [0.1963, 0.2507, 0.5797],\n",
      "        [0.4239, 0.7247, 0.2615]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个随机初始化的 5*3 矩阵\n",
    "rand_x = torch.rand(5, 3)\n",
    "print(rand_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.zeros():创建数值都是0的矩阵\n",
    "- torch.ones(): 创建数值都是1的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个数值皆是 0，类型为 long 的矩阵\n",
    "zero_x=torch.zeros(5,3,dtype=torch.long)\n",
    "print(zero_x)\n",
    "ones_x=torch.ones(5,3,dtype=torch.long)\n",
    "print(ones_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.tesor()：直接传递tensor数值来创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# tensor数值是[5.5,3]\n",
    "tensor1 = torch.tensor([5.5,3])\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了上述几种方法，还可以根据已有的 tensor 变量创建新的 tensor 变量，这种做法的好处就是可以保留已有 tensor 的一些属性，包括尺寸大小、数值属性，除非是重新定义这些属性。相应的实现方法如下：\n",
    "\n",
    "- tensor.new_ones()：new_*()方法需要输入尺寸大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 显示定义新的尺寸是 5*3，数据类型是 torch.double\n",
    "tensor2 =tensor1.new_ones(5,3,dtype=torch.double) #new_* 方法需要输入tensor大小\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.randn_like(old_tensor)：保留相同尺寸大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor3: tensor([[-1.1706,  0.9815,  0.7736],\n",
      "        [-0.2437,  2.3403, -0.7077],\n",
      "        [-0.1417,  0.7037, -1.0424],\n",
      "        [-0.1855, -0.8306, -0.5581],\n",
      "        [ 0.0416,  1.4710,  0.6713]])\n"
     ]
    }
   ],
   "source": [
    "#改变数值类型\n",
    "tensor3 = torch.randn_like(tensor2,dtype=torch.float)\n",
    "print('tensor3:',tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensor.size()：获取tensors的尺寸大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(tensor3.size())  \n",
    "# 输出: torch.Size([5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**： torch.Size 实际上是**元组(tuple)**类型，所以支持所有的元组操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.2 操作**###\n",
    "1. 加法\n",
    "实现方式：\n",
    "- +运算符\n",
    "- **torch.add(tensor1,tensor2,[out=tensor3])**\n",
    "- **tensor1.add_(tensor2)：直接修改tensor变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor3 + tensor4=  tensor([[-0.3419,  1.2197,  1.2670],\n",
      "        [ 0.2640,  2.7703, -0.0894],\n",
      "        [ 0.1059,  1.1563, -0.4881],\n",
      "        [ 0.5277, -0.2235, -0.0629],\n",
      "        [ 0.6651,  1.6290,  1.2684]])\n",
      "tensor3 + tensor4=  tensor([[-0.3419,  1.2197,  1.2670],\n",
      "        [ 0.2640,  2.7703, -0.0894],\n",
      "        [ 0.1059,  1.1563, -0.4881],\n",
      "        [ 0.5277, -0.2235, -0.0629],\n",
      "        [ 0.6651,  1.6290,  1.2684]])\n",
      "add result=  tensor([[-0.3419,  1.2197,  1.2670],\n",
      "        [ 0.2640,  2.7703, -0.0894],\n",
      "        [ 0.1059,  1.1563, -0.4881],\n",
      "        [ 0.5277, -0.2235, -0.0629],\n",
      "        [ 0.6651,  1.6290,  1.2684]])\n",
      "tensor3=  tensor([[-0.3419,  1.2197,  1.2670],\n",
      "        [ 0.2640,  2.7703, -0.0894],\n",
      "        [ 0.1059,  1.1563, -0.4881],\n",
      "        [ 0.5277, -0.2235, -0.0629],\n",
      "        [ 0.6651,  1.6290,  1.2684]])\n"
     ]
    }
   ],
   "source": [
    "tensor4 = torch.rand(5, 3)\n",
    "print('tensor3 + tensor4= ', tensor3 + tensor4)\n",
    "print('tensor3 + tensor4= ', torch.add(tensor3, tensor4))\n",
    "# 新声明一个 tensor 变量保存加法操作的结果\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(tensor3, tensor4, out=result)\n",
    "print('add result= ', result)\n",
    "# 直接修改变量\n",
    "tensor3.add_(tensor4)\n",
    "print('tensor3= ', tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**：可以改变 tensor 变量的操作都带有一个后缀 _, 例如 x.copy_(y), x.t_() 都可以改变 x 变量\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 Tensor 的访问，和 Numpy 对数组类似，可以使用索引来访问某一维的数据，如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3419,  0.2640,  0.1059,  0.5277,  0.6651])\n"
     ]
    }
   ],
   "source": [
    "# 访问 tensor3 第一列数据\n",
    "print(tensor3[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-torch.view()：修改Tensor的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "# -1 表示除给定维度外的其余维度的乘积\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensor.item()：对只有一个元素的tensor获取一个类似py中的整数类型的数值\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5737])\n",
      "0.573727011680603\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 **和Numpy数组的转换**\n",
    "Tensor 和 Numpy 的数组可以相互转换，并且两者转换后共享在 CPU 下的内存空间，即改变其中一个的数值，另一个变量也会随之改变。\n",
    "\n",
    "### 1.3.1 **Tensor转换为Numpy数组**\n",
    "-tensor.numpy():Tensor->Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 **Numpy数组转换为Tensor**\n",
    "- torch.from_numpy(numpy_array)：Numpy->Tensor\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 **CUDA张量**\n",
    "Tensors 可以通过 .to 方法转换到不同的设备上，即 CPU 或者 GPU 上。例子如下所示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 当 CUDA 可用的时候，可用运行下方这段代码，采用 torch.device() 方法来改变 tensors 是否在 GPU 上进行计算操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5737], device='cuda:0')\n",
      "tensor([1.5737], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # 定义一个 CUDA 设备对象\n",
    "    y = torch.ones_like(x, device=device)  # 显示创建在 GPU 上的一个 tensor\n",
    "    x = x.to(device)                       # 也可以采用 .to(\"cuda\") \n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # .to() 方法也可以改变数值类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出结果，第一个结果就是在 GPU 上的结果，打印变量的时候会带有 device='cuda:0'，而第二个是在 CPU 上的变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([1.4549], device='cuda:0')\n",
    "tensor([1.4549], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONV：卷积计算层，线性乘积求和。\n",
    "RELU：激励层，ReLU是激活函数的一种。\n",
    "POOL：池化层，简言之，即取区域平均或最大。\n",
    "PCA/白化等等。CNN只对训练集做“去均值”这一步\n",
    "FC：全连接层\n",
    "这几个部分中，卷积计算层是CNN（神经网络）的核心，下文将重点阐述。\n",
    "未知图案的局部和标准X图案的局部一个一个比对时的计算过程，便是卷积操作\n",
    "3.2 什么是卷积\n",
    "对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源。\n",
    "a. 深度depth：神经元个数，决定输出的depth厚度，同时代表滤波器个数。\n",
    "b. 步长stride：决定滑动多少步可以到边缘。\n",
    "c. 填充值zero-padding：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。\n",
    "\n",
    "左边数据在变化，每次滤波器都是针对某一局部的数据窗口进行卷积，这就是所谓的CNN中的局部感知机制。\n",
    "\n",
    "打个比方，滤波器就像一双眼睛，人类视角有限，一眼望去，只能看到这世界的局部。如果一眼就看到全世界，你会累死，而且一下子接受全世界所有信息，你大脑接收不过来。当然，即便是看局部，针对局部里的信息人类双眼也是有偏重、偏好的。比如看美女，对脸、胸、腿是重点关注，所以这3个输入的权重相对较大。\n",
    "\n",
    "nn.Flatten()作用：将连续的维度范围展平为张量。 经常在nn.Sequential()中出现，一般写在某个神经网络模型之后，用于对神经网络模型的输出进行处理，得到tensor类型的数据。\n",
    "\n",
    "生成器，迭代器\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
